{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"CSDMS 2021: Changing Landscapes and Seascapes Modeling for Discovery, Decision Making, and Communication \u00b6 May 17 -21th 2021 Clinic: An Introduction to using Google Earth Engine Before the Clinic \u00b6 Make sure you have Google Chrome and update it just incase, Google Earth Engine (GEE) works on others browser but has issues once in a while. If you don\u2019t have a GEE account sign up for one developer account sign up for one here Once you have a Google Earth Engine account click this link and add find how to add the clinic repository to your account. Google Earth Engine Browser Based Remote Sensing \u00b6 I like to tell people that Google Earth Engine does browser based remote sensing , because all you need is an active internet connection and a browser to run this. To bring us to a fair playing field when it comes to analyzing and repeating data analysis. Google Earth Engine is a cloud based analysis platform that allows for an indexable and queryable raster and vector environment while including and expanding on raster capabilities. It allows for users to perform large scale analysis on multiple assets a large number of which it actively ingests and maintains. While maintaining one of the world's largest repository of open source and distributable datasets, it allows you to scale and fit analysis based on your needs from local to global analysis. The analysis is performed using a JavaScript or python environment depending on the need and the results are repeatable and shareable as research outputs. You can read more about the Google Earth Engine platform here","title":"Introduction"},{"location":"#csdms-2021-changing-landscapes-and-seascapes-modeling-for-discovery-decision-making-and-communication","text":"May 17 -21th 2021 Clinic: An Introduction to using Google Earth Engine","title":"CSDMS 2021: Changing Landscapes and Seascapes Modeling for Discovery, Decision Making, and Communication"},{"location":"#before-the-clinic","text":"Make sure you have Google Chrome and update it just incase, Google Earth Engine (GEE) works on others browser but has issues once in a while. If you don\u2019t have a GEE account sign up for one developer account sign up for one here Once you have a Google Earth Engine account click this link and add find how to add the clinic repository to your account.","title":"Before the Clinic"},{"location":"#google-earth-engine-browser-based-remote-sensing","text":"I like to tell people that Google Earth Engine does browser based remote sensing , because all you need is an active internet connection and a browser to run this. To bring us to a fair playing field when it comes to analyzing and repeating data analysis. Google Earth Engine is a cloud based analysis platform that allows for an indexable and queryable raster and vector environment while including and expanding on raster capabilities. It allows for users to perform large scale analysis on multiple assets a large number of which it actively ingests and maintains. While maintaining one of the world's largest repository of open source and distributable datasets, it allows you to scale and fit analysis based on your needs from local to global analysis. The analysis is performed using a JavaScript or python environment depending on the need and the results are repeatable and shareable as research outputs. You can read more about the Google Earth Engine platform here","title":"Google Earth Engine Browser Based Remote Sensing"},{"location":"citations/","text":"Citations \u00b6 To cite Google Earth Engine, use the following: Gorelick, Noel, Matt Hancher, Mike Dixon, Simon Ilyushchenko, David Thau, and Rebecca Moore. \"Google Earth Engine: Planetary-scale geospatial analysis for everyone.\" Remote Sensing of Environment 202 (2017): 18-27.","title":"Citations"},{"location":"citations/#citations","text":"To cite Google Earth Engine, use the following: Gorelick, Noel, Matt Hancher, Mike Dixon, Simon Ilyushchenko, David Thau, and Rebecca Moore. \"Google Earth Engine: Planetary-scale geospatial analysis for everyone.\" Remote Sensing of Environment 202 (2017): 18-27.","title":"Citations"},{"location":"contact/","text":"Contact Us \u00b6 Contact me directly \u00b6 Samapriya Roy: samapriya.roy@gmail.com Follow me on twitter to get updates on new projects: Or find me on LinkedIn: or go to Doug's page https://earth.indiana.edu/directory/faculty/edmonds-douglas.html Also reach out for support by joining the google group below \u00b6 google-earth-engine-developers@googlegroups.com","title":"Contact Us"},{"location":"contact/#contact-us","text":"","title":"Contact Us"},{"location":"contact/#contact-me-directly","text":"Samapriya Roy: samapriya.roy@gmail.com Follow me on twitter to get updates on new projects: Or find me on LinkedIn: or go to Doug's page https://earth.indiana.edu/directory/faculty/edmonds-douglas.html","title":"Contact me directly"},{"location":"contact/#also-reach-out-for-support-by-joining-the-google-group-below","text":"google-earth-engine-developers@googlegroups.com","title":"Also reach out for support by joining the google group below"},{"location":"projects/community/","text":"Community Datasets \u00b6 This is one step beyond archiving data on a personal website or within a data center as mandated by many funding agencies. For example: You should still start by having a DOI associated with the data either by publishing it as a part of a peer-reviewed paper or by using a service like Zenodo. Then, regardless of where you created your final product, you would upload your dataset details into our digital commons list and citations are included. Even if you aren\u2019t the dataset author, you can still suggest products because you are using them within your project. Creating shared cloud-based assets saves everyone time and effort. Examples of this include basic information on shorelines and rivers. Many projects use simplistic information on shorelines or duplicate efforts by uploading their own version of river centerlines and extent. Using data which has been systematically generated globally has major benefits, especially if it was derived using modern techniques. This improves the quality of our science. Go to the Github Page to check the project and contribute","title":"Community Datasets"},{"location":"projects/community/#community-datasets","text":"This is one step beyond archiving data on a personal website or within a data center as mandated by many funding agencies. For example: You should still start by having a DOI associated with the data either by publishing it as a part of a peer-reviewed paper or by using a service like Zenodo. Then, regardless of where you created your final product, you would upload your dataset details into our digital commons list and citations are included. Even if you aren\u2019t the dataset author, you can still suggest products because you are using them within your project. Creating shared cloud-based assets saves everyone time and effort. Examples of this include basic information on shorelines and rivers. Many projects use simplistic information on shorelines or duplicate efforts by uploading their own version of river centerlines and extent. Using data which has been systematically generated globally has major benefits, especially if it was derived using modern techniques. This improves the quality of our science. Go to the Github Page to check the project and contribute","title":"Community Datasets"},{"location":"projects/export/","text":"Exporting Image & Visualization \u00b6 When we are all said and done we still want to export the images. Google Earth Engine allows you to export images externally into two subsystems, a Google Cloud Storage Bucket or Google Drive. The method we are exploring right now is export to Google Drive, and then being able to import the analyzed image into any local tool or libraries. It is possible to export entire collections to drive using batch exports in the python API client. This avoids the need for you to click on the Run button every time an export task has to be started. For this setup we are going to export the Sentinel-2 mosaic imagery at a 20m resolution var s2 = ee . ImageCollection ( \"COPERNICUS/S2_SR\" ); var geometry = ee . Geometry . Polygon ( [[[ - 89.79297430041262 , 29.677212347812258 ], [ - 89.79297430041262 , 28.850584616352855 ], [ - 88.91681463244387 , 28.850584616352855 ], [ - 88.91681463244387 , 29.677212347812258 ]]], null , false ); var rgbVis = { \"opacity\" : 1 , \"bands\" : [ \"B4\" , \"B3\" , \"B2\" ], \"min\" : 1 , \"max\" : 1506 , \"gamma\" : 1.786 }; //********************************* Image Collection*****************************************// Map . centerObject ( geometry , 10 ) //Let's constrain the Sentinel-2 SR collection by our geometry & a cloudy pixel percentage metadata var collection = s2 . filter ( ee . Filter . bounds ( geometry )) . filter ( ee . Filter . date ( '2020-01-01' , '2021-01-01' )) . filter ( ee . Filter . lt ( 'CLOUDY_PIXEL_PERCENTAGE' , 5 )) . select ( 'B.*' ) //Also let us only add optical bands wildcard to filter only bands starting with B print ( 'Total filtered images in collection' , collection . size ()) /* Things to keep in mind, image collections are usually sorted by default based on date Mosaic function adds the latest pixels or most recent image on top while trying to mosaic */ var mosaic = collection . mosaic () Map . addLayer ( collection , rgbVis , 'Filtered Collection' ); Map . addLayer ( mosaic . clip ( geometry ), rgbVis , 'Mosaic' , false ); //Using the visualize function means you have forced the image to be visualized in a specific way var visualized = mosaic . clip ( geometry ). visualize ( rgbVis ) //You can export the visualized image so that you get something that looks similar to how it would appear in GEE Export . image . toDrive ({ image : visualized . clip ( geometry ), description : 'Export-Median-Composite-Visualized' , folder : 'csdms2021' , fileNamePrefix : 'median_composite_visualized' , region : geometry , scale : 20 , maxPixels : 1e12 }) //Or you can export the image only Export . image . toDrive ({ image : mosaic . clip ( geometry ), description : 'Export-Median-Composite' , folder : 'csdms2021' , fileNamePrefix : 'median_composite' , region : geometry , scale : 20 , maxPixels : 1e12 })","title":"Exporting Image & Visualization"},{"location":"projects/export/#exporting-image-visualization","text":"When we are all said and done we still want to export the images. Google Earth Engine allows you to export images externally into two subsystems, a Google Cloud Storage Bucket or Google Drive. The method we are exploring right now is export to Google Drive, and then being able to import the analyzed image into any local tool or libraries. It is possible to export entire collections to drive using batch exports in the python API client. This avoids the need for you to click on the Run button every time an export task has to be started. For this setup we are going to export the Sentinel-2 mosaic imagery at a 20m resolution var s2 = ee . ImageCollection ( \"COPERNICUS/S2_SR\" ); var geometry = ee . Geometry . Polygon ( [[[ - 89.79297430041262 , 29.677212347812258 ], [ - 89.79297430041262 , 28.850584616352855 ], [ - 88.91681463244387 , 28.850584616352855 ], [ - 88.91681463244387 , 29.677212347812258 ]]], null , false ); var rgbVis = { \"opacity\" : 1 , \"bands\" : [ \"B4\" , \"B3\" , \"B2\" ], \"min\" : 1 , \"max\" : 1506 , \"gamma\" : 1.786 }; //********************************* Image Collection*****************************************// Map . centerObject ( geometry , 10 ) //Let's constrain the Sentinel-2 SR collection by our geometry & a cloudy pixel percentage metadata var collection = s2 . filter ( ee . Filter . bounds ( geometry )) . filter ( ee . Filter . date ( '2020-01-01' , '2021-01-01' )) . filter ( ee . Filter . lt ( 'CLOUDY_PIXEL_PERCENTAGE' , 5 )) . select ( 'B.*' ) //Also let us only add optical bands wildcard to filter only bands starting with B print ( 'Total filtered images in collection' , collection . size ()) /* Things to keep in mind, image collections are usually sorted by default based on date Mosaic function adds the latest pixels or most recent image on top while trying to mosaic */ var mosaic = collection . mosaic () Map . addLayer ( collection , rgbVis , 'Filtered Collection' ); Map . addLayer ( mosaic . clip ( geometry ), rgbVis , 'Mosaic' , false ); //Using the visualize function means you have forced the image to be visualized in a specific way var visualized = mosaic . clip ( geometry ). visualize ( rgbVis ) //You can export the visualized image so that you get something that looks similar to how it would appear in GEE Export . image . toDrive ({ image : visualized . clip ( geometry ), description : 'Export-Median-Composite-Visualized' , folder : 'csdms2021' , fileNamePrefix : 'median_composite_visualized' , region : geometry , scale : 20 , maxPixels : 1e12 }) //Or you can export the image only Export . image . toDrive ({ image : mosaic . clip ( geometry ), description : 'Export-Median-Composite' , folder : 'csdms2021' , fileNamePrefix : 'median_composite' , region : geometry , scale : 20 , maxPixels : 1e12 })","title":"Exporting Image &amp; Visualization"},{"location":"projects/feature_collection/","text":"Feature Collections in Earth Engine \u00b6 Feature Collections are similar to Image Collections - but they contain Features, not images. They are equivalent to Vector Layers in a GIS. We can load, filter and display Feature Collections using similar techniques that we have learned so far. Similar to bringing in your own images and creating image collections, it is possible to upload shapefiles and CSV tables directly into earth engine enriching the list of datasets made available to you. For this example we chose to use the Hydrologic Unit Code or HUC boundaries already preingested in Google Earth Engine. I decided to use HUC 6 but you can choose a scale depending on your question of interest. var s2 = ee . ImageCollection ( \"COPERNICUS/S2_SR\" ); var geometry = ee . Geometry . Polygon ( [[[ - 89.79297430041262 , 29.677212347812258 ], [ - 89.79297430041262 , 28.850584616352855 ], [ - 88.91681463244387 , 28.850584616352855 ], [ - 88.91681463244387 , 29.677212347812258 ]]], null , false ); var vis = { \"opacity\" : 1 , \"bands\" : [ \"B8\" , \"B3\" , \"B2\" ], \"min\" : 1 , \"max\" : 2870 , \"gamma\" : 1.4140000000000001 }; var HUC6 = ee . FeatureCollection ( \"USGS/WBD/2017/HUC06\" ); var image = ee . Image ( 'COPERNICUS/S2_SR/20190831T162839_20190831T164212_T16RBT' ) print ( 'Total HUC 6 Features' , HUC6 . size ()) //Add all HUC6 features that intersects with our geometry & create a transparent overlay Map . addLayer ( HUC6 . filterBounds ( geometry ). style ({ fillColor : '00000000' , color : 'FF5500' }),{}, 'HUC 6 Transparent Overlay' , false ); //Now clip the image we first added using the feature collection Map . addLayer ( image . clip ( HUC6 . filterBounds ( geometry )), vis , \"HUC 6 Clipped S2-SR Image 2019-08-31\" , false )","title":"Feature Collection"},{"location":"projects/feature_collection/#feature-collections-in-earth-engine","text":"Feature Collections are similar to Image Collections - but they contain Features, not images. They are equivalent to Vector Layers in a GIS. We can load, filter and display Feature Collections using similar techniques that we have learned so far. Similar to bringing in your own images and creating image collections, it is possible to upload shapefiles and CSV tables directly into earth engine enriching the list of datasets made available to you. For this example we chose to use the Hydrologic Unit Code or HUC boundaries already preingested in Google Earth Engine. I decided to use HUC 6 but you can choose a scale depending on your question of interest. var s2 = ee . ImageCollection ( \"COPERNICUS/S2_SR\" ); var geometry = ee . Geometry . Polygon ( [[[ - 89.79297430041262 , 29.677212347812258 ], [ - 89.79297430041262 , 28.850584616352855 ], [ - 88.91681463244387 , 28.850584616352855 ], [ - 88.91681463244387 , 29.677212347812258 ]]], null , false ); var vis = { \"opacity\" : 1 , \"bands\" : [ \"B8\" , \"B3\" , \"B2\" ], \"min\" : 1 , \"max\" : 2870 , \"gamma\" : 1.4140000000000001 }; var HUC6 = ee . FeatureCollection ( \"USGS/WBD/2017/HUC06\" ); var image = ee . Image ( 'COPERNICUS/S2_SR/20190831T162839_20190831T164212_T16RBT' ) print ( 'Total HUC 6 Features' , HUC6 . size ()) //Add all HUC6 features that intersects with our geometry & create a transparent overlay Map . addLayer ( HUC6 . filterBounds ( geometry ). style ({ fillColor : '00000000' , color : 'FF5500' }),{}, 'HUC 6 Transparent Overlay' , false ); //Now clip the image we first added using the feature collection Map . addLayer ( image . clip ( HUC6 . filterBounds ( geometry )), vis , \"HUC 6 Clipped S2-SR Image 2019-08-31\" , false )","title":"Feature Collections in Earth Engine"},{"location":"projects/functions/","text":"Functions & Mapping \u00b6 While single image operations are direct and can be applied to the imagery for a one to one result. Applying any kind of analysis on a single image means you have to call the image and run the analysis which is quick and easy. To be able to turn this same into a function that you can iterate over an entire collection requires us to convert a single analysis to a function. A function is then mapped or run over an entire collection. To avoid any errors make sure that the collection images are consistent and have same name and number of band and characteristics. For this setup we look at how we could apply cloud masking to Sentinel-2 using the Snow and Cloud Probability bands. var s2 = ee . ImageCollection ( \"COPERNICUS/S2_SR\" ); var geometry = ee . Geometry . Polygon ( [[[ - 89.79297430041262 , 29.677212347812258 ], [ - 89.79297430041262 , 28.850584616352855 ], [ - 88.91681463244387 , 28.850584616352855 ], [ - 88.91681463244387 , 29.677212347812258 ]]], null , false ); var rgbVis = { \"opacity\" : 1 , \"bands\" : [ \"B4\" , \"B3\" , \"B2\" ], \"min\" : 1 , \"max\" : 1506 , \"gamma\" : 1.786 }; //********************************* Image Collection*****************************************// Map . centerObject ( geometry , 10 ) //Let's constrain the Sentinel-2 SR collection by our geometry & a cloudy pixel percentage metadata var collection = s2 . filter ( ee . Filter . bounds ( geometry )) . filter ( ee . Filter . date ( '2020-01-01' , '2021-01-01' )) . filter ( ee . Filter . lt ( 'CLOUDY_PIXEL_PERCENTAGE' , 5 )) print ( 'Total filter images in collection' , collection . size ()) //Introducing functions & Mapping over functions // Function to remove cloud and snow pixels from Sentinel-2 SR image function masks2 ( image ) { var cloudProb = image . select ( 'MSK_CLDPRB' ); var snowProb = image . select ( 'MSK_SNWPRB' ); var cloud = cloudProb . lt ( 1 ); var snow = snowProb . lt ( 1 ); var scl = image . select ( 'SCL' ); var shadow = scl . eq ( 3 ); // 3 = cloud shadow var cirrus = scl . eq ( 10 ); // 10 = cirrus // Cloud probability less than 1% or cloud shadow classification var mask = ( cloud . and ( snow )). and ( cirrus . neq ( 1 )). and ( shadow . neq ( 1 )); return image . updateMask ( mask ); } collection = collection . map ( masks2 ) /* Things to keep in mind, image collections are usually sorted by default based on date Mosaic function adds the latest pixels or most recent image on top while trying to mosaic Median composite on the other hands takes the median value of pixel over the time period */ var mosaic = collection . mosaic () var medianComposite = collection . median (); Map . addLayer ( collection , rgbVis , 'Filtered Collection' ); Map . addLayer ( mosaic . clip ( geometry ), rgbVis , 'Mosaic' , false ); Map . addLayer ( medianComposite . clip ( geometry ), rgbVis , 'Median Composite' , false )","title":"Functions & Mapping"},{"location":"projects/functions/#functions-mapping","text":"While single image operations are direct and can be applied to the imagery for a one to one result. Applying any kind of analysis on a single image means you have to call the image and run the analysis which is quick and easy. To be able to turn this same into a function that you can iterate over an entire collection requires us to convert a single analysis to a function. A function is then mapped or run over an entire collection. To avoid any errors make sure that the collection images are consistent and have same name and number of band and characteristics. For this setup we look at how we could apply cloud masking to Sentinel-2 using the Snow and Cloud Probability bands. var s2 = ee . ImageCollection ( \"COPERNICUS/S2_SR\" ); var geometry = ee . Geometry . Polygon ( [[[ - 89.79297430041262 , 29.677212347812258 ], [ - 89.79297430041262 , 28.850584616352855 ], [ - 88.91681463244387 , 28.850584616352855 ], [ - 88.91681463244387 , 29.677212347812258 ]]], null , false ); var rgbVis = { \"opacity\" : 1 , \"bands\" : [ \"B4\" , \"B3\" , \"B2\" ], \"min\" : 1 , \"max\" : 1506 , \"gamma\" : 1.786 }; //********************************* Image Collection*****************************************// Map . centerObject ( geometry , 10 ) //Let's constrain the Sentinel-2 SR collection by our geometry & a cloudy pixel percentage metadata var collection = s2 . filter ( ee . Filter . bounds ( geometry )) . filter ( ee . Filter . date ( '2020-01-01' , '2021-01-01' )) . filter ( ee . Filter . lt ( 'CLOUDY_PIXEL_PERCENTAGE' , 5 )) print ( 'Total filter images in collection' , collection . size ()) //Introducing functions & Mapping over functions // Function to remove cloud and snow pixels from Sentinel-2 SR image function masks2 ( image ) { var cloudProb = image . select ( 'MSK_CLDPRB' ); var snowProb = image . select ( 'MSK_SNWPRB' ); var cloud = cloudProb . lt ( 1 ); var snow = snowProb . lt ( 1 ); var scl = image . select ( 'SCL' ); var shadow = scl . eq ( 3 ); // 3 = cloud shadow var cirrus = scl . eq ( 10 ); // 10 = cirrus // Cloud probability less than 1% or cloud shadow classification var mask = ( cloud . and ( snow )). and ( cirrus . neq ( 1 )). and ( shadow . neq ( 1 )); return image . updateMask ( mask ); } collection = collection . map ( masks2 ) /* Things to keep in mind, image collections are usually sorted by default based on date Mosaic function adds the latest pixels or most recent image on top while trying to mosaic Median composite on the other hands takes the median value of pixel over the time period */ var mosaic = collection . mosaic () var medianComposite = collection . median (); Map . addLayer ( collection , rgbVis , 'Filtered Collection' ); Map . addLayer ( mosaic . clip ( geometry ), rgbVis , 'Mosaic' , false ); Map . addLayer ( medianComposite . clip ( geometry ), rgbVis , 'Median Composite' , false )","title":"Functions &amp; Mapping"},{"location":"projects/housekeeping/","text":"Basic Housekeeping \u00b6 For most users data usage often boils down to the software you use to analyze and manipulate images and how you are going to work with them. So here are going to do some housekeeping and setup depending on which tools and setup you are most comfortable with 1) Google Earth Engine(GEE) Command Line Interface(CLI) Setup \u00b6 This assumes that you have registered for a Google Earth Engine account but also installed its client. Incase you have missed it go to their main reference page for installation of their python client . Since you can consume Earth Engine using both Javascript(in browser) and Python(locally) the interaction would depend on the scale of your tasks and what you wish your achieve as your end result. Once installed make sure you authenticate your earth engine client and then your CLI should give you the following options 2) Adding additional Images \u00b6 For the simplest users getting images into GEE begins with the Image upload tool located inside GEE. Once you have added the filename you can edit additional metadata such as start time, cloud cover information if you have that from the metadata file among other things. This tool does not have a way for you to ingest any metadata automatically so it has to be fed manually. The image name is automatically filled in with the filename that you select when uploading. Note you cannot select more than one image and upload as a single image if they overlap each other. To handle which we have the concept of image collections. Where you can upload many images. To import images into collections, you have to either import them manually as images first and then copy them into the collection one by one or for now use an external tool to help such as using the Google Earth Engine CLI. Incase you have a Google Cloud Storage bucket you can also push images automatically to be ingested into GEE. Though this requires interaction with gsutil and starting ingestion function for each image. The GEE guide for image ingestion can be found here","title":"Basic Housekeeping"},{"location":"projects/housekeeping/#basic-housekeeping","text":"For most users data usage often boils down to the software you use to analyze and manipulate images and how you are going to work with them. So here are going to do some housekeeping and setup depending on which tools and setup you are most comfortable with","title":"Basic Housekeeping"},{"location":"projects/housekeeping/#1-google-earth-enginegee-command-line-interfacecli-setup","text":"This assumes that you have registered for a Google Earth Engine account but also installed its client. Incase you have missed it go to their main reference page for installation of their python client . Since you can consume Earth Engine using both Javascript(in browser) and Python(locally) the interaction would depend on the scale of your tasks and what you wish your achieve as your end result. Once installed make sure you authenticate your earth engine client and then your CLI should give you the following options","title":"1) Google Earth Engine(GEE) Command Line Interface(CLI) Setup"},{"location":"projects/housekeeping/#2-adding-additional-images","text":"For the simplest users getting images into GEE begins with the Image upload tool located inside GEE. Once you have added the filename you can edit additional metadata such as start time, cloud cover information if you have that from the metadata file among other things. This tool does not have a way for you to ingest any metadata automatically so it has to be fed manually. The image name is automatically filled in with the filename that you select when uploading. Note you cannot select more than one image and upload as a single image if they overlap each other. To handle which we have the concept of image collections. Where you can upload many images. To import images into collections, you have to either import them manually as images first and then copy them into the collection one by one or for now use an external tool to help such as using the Google Earth Engine CLI. Incase you have a Google Cloud Storage bucket you can also push images automatically to be ingested into GEE. Though this requires interaction with gsutil and starting ingestion function for each image. The GEE guide for image ingestion can be found here","title":"2) Adding additional Images"},{"location":"projects/imagecollection/","text":"Image Collections in Earth Engine \u00b6 While single images are great to do quick analytics, the true power of the Earth Engine environment comes with the possibility of looking at really large and heavy image collections and to be able to push analysis towards the data, rather than the need for the data to travel at all. In the GEE environment image collections have their own characteristic setup and are composted with single images that we discussed earlier. They can often have the same or different band structure but generally share a similar metadata structure for filtering and querying. Large scale image collections such as Landsat and Sentinel image collections are ingested on the fly and are actively maintained till there imagery and processing pipelines feeds are maintained byt he agencies supplying the imagery. Images as well as image collections can be moved into GEE environment to allow you to use both your data and the GEE catalog data within the same platform. For those who are concerned with access to datasets, this means that though Earth Engine allows an easier way to share datasets across users, private folder, collections and imagery are private and are not here the section from their Terms and Conditions page Intellectual Property Rights. Except as expressly set forth in this Agreement, this Agreement does not grant either party any rights, implied or otherwise, to the other\u2019s content or any of the other\u2019s intellectual property. As between the parties, Customer owns all Intellectual Property Rights in Customer Data, Customer Code, and Application(s), and Google owns all Intellectual Property Rights in the Services and Software. These image collection as well as individual imaegs again have defined data type,scales and projections along with some default properties such as an index and ID among other system properties. So we can query these properties, print them and add them var s2 = ee . ImageCollection ( \"COPERNICUS/S2_SR\" ); var geometry = ee . Geometry . Polygon ( [[[ - 89.79297430041262 , 29.677212347812258 ], [ - 89.79297430041262 , 28.850584616352855 ], [ - 88.91681463244387 , 28.850584616352855 ], [ - 88.91681463244387 , 29.677212347812258 ]]], null , false ); var vis = { \"opacity\" : 1 , \"bands\" : [ \"B8\" , \"B3\" , \"B2\" ], \"min\" : 1 , \"max\" : 2870 , \"gamma\" : 1.4140000000000001 }; //Let's constrain the Sentinel-2 SR collection by our geometry & a cloudy pixel percentage metadata var collection = s2 . filter ( ee . Filter . bounds ( geometry )) . filter ( ee . Filter . lt ( 'CLOUDY_PIXEL_PERCENTAGE' , 5 )) print ( collection . size ()) //Prints the size of the collection //Remember the collection has been constrained to our geometry & cloudy pixel % //Print & add the first element from the collection Map . centerObject ( geometry , 10 ) print ( 'First image from Collection' , collection . first ()) Map . addLayer ( collection . first (). clip ( geometry ), vis , 'First image from Collection' ) To have a look at all of the raster catalog you can find them listed here","title":"Image Collection"},{"location":"projects/imagecollection/#image-collections-in-earth-engine","text":"While single images are great to do quick analytics, the true power of the Earth Engine environment comes with the possibility of looking at really large and heavy image collections and to be able to push analysis towards the data, rather than the need for the data to travel at all. In the GEE environment image collections have their own characteristic setup and are composted with single images that we discussed earlier. They can often have the same or different band structure but generally share a similar metadata structure for filtering and querying. Large scale image collections such as Landsat and Sentinel image collections are ingested on the fly and are actively maintained till there imagery and processing pipelines feeds are maintained byt he agencies supplying the imagery. Images as well as image collections can be moved into GEE environment to allow you to use both your data and the GEE catalog data within the same platform. For those who are concerned with access to datasets, this means that though Earth Engine allows an easier way to share datasets across users, private folder, collections and imagery are private and are not here the section from their Terms and Conditions page Intellectual Property Rights. Except as expressly set forth in this Agreement, this Agreement does not grant either party any rights, implied or otherwise, to the other\u2019s content or any of the other\u2019s intellectual property. As between the parties, Customer owns all Intellectual Property Rights in Customer Data, Customer Code, and Application(s), and Google owns all Intellectual Property Rights in the Services and Software. These image collection as well as individual imaegs again have defined data type,scales and projections along with some default properties such as an index and ID among other system properties. So we can query these properties, print them and add them var s2 = ee . ImageCollection ( \"COPERNICUS/S2_SR\" ); var geometry = ee . Geometry . Polygon ( [[[ - 89.79297430041262 , 29.677212347812258 ], [ - 89.79297430041262 , 28.850584616352855 ], [ - 88.91681463244387 , 28.850584616352855 ], [ - 88.91681463244387 , 29.677212347812258 ]]], null , false ); var vis = { \"opacity\" : 1 , \"bands\" : [ \"B8\" , \"B3\" , \"B2\" ], \"min\" : 1 , \"max\" : 2870 , \"gamma\" : 1.4140000000000001 }; //Let's constrain the Sentinel-2 SR collection by our geometry & a cloudy pixel percentage metadata var collection = s2 . filter ( ee . Filter . bounds ( geometry )) . filter ( ee . Filter . lt ( 'CLOUDY_PIXEL_PERCENTAGE' , 5 )) print ( collection . size ()) //Prints the size of the collection //Remember the collection has been constrained to our geometry & cloudy pixel % //Print & add the first element from the collection Map . centerObject ( geometry , 10 ) print ( 'First image from Collection' , collection . first ()) Map . addLayer ( collection . first (). clip ( geometry ), vis , 'First image from Collection' ) To have a look at all of the raster catalog you can find them listed here","title":"Image Collections in Earth Engine"},{"location":"projects/images/","text":"Images in Earth Engine \u00b6 In the GEE environment images are stored in Cloud Optimized Geospatial tiles instead of a single image which allows for running an analysis this scale. This means that though the input imagery comes in know formats such as geotiff , MrSid and img these datasets post ingestion into GEE are converted into tiles that are used for at scale analysis. All images that are ingested into either GEE(s) Raster Catalog or your own personal folder and stored in folder or collections of images as you would expect to see when doing deep time stack analysis. These images have defined data type,scales and projections along with some default properties such as an index and ID among other system properties. So we can query these properties, print them and add them var s2 = ee . ImageCollection ( \"COPERNICUS/S2_SR\" ); var geometry = ee . Geometry . Polygon ( [[[ - 89.79297430041262 , 29.677212347812258 ], [ - 89.79297430041262 , 28.850584616352855 ], [ - 88.91681463244387 , 28.850584616352855 ], [ - 88.91681463244387 , 29.677212347812258 ]]], null , false ); var vis = { \"opacity\" : 1 , \"bands\" : [ \"B8\" , \"B3\" , \"B2\" ], \"min\" : 1 , \"max\" : 2870 , \"gamma\" : 1.4140000000000001 }; var image = ee . Image ( 'COPERNICUS/S2_SR/20190831T162839_20190831T164212_T16RBT' ) print ( 'Single Image' , image ) //Center the Map to the image and add the image Map . centerObject ( geometry , 10 ) Map . addLayer ( image , vis , \"S2-SR Image 2019-08-31\" ) //Clip an image var clipped = image . clip ( geometry ) Map . addLayer ( clipped , vis , \"Clipped S2-SR Image 2019-08-31\" )","title":"Images"},{"location":"projects/images/#images-in-earth-engine","text":"In the GEE environment images are stored in Cloud Optimized Geospatial tiles instead of a single image which allows for running an analysis this scale. This means that though the input imagery comes in know formats such as geotiff , MrSid and img these datasets post ingestion into GEE are converted into tiles that are used for at scale analysis. All images that are ingested into either GEE(s) Raster Catalog or your own personal folder and stored in folder or collections of images as you would expect to see when doing deep time stack analysis. These images have defined data type,scales and projections along with some default properties such as an index and ID among other system properties. So we can query these properties, print them and add them var s2 = ee . ImageCollection ( \"COPERNICUS/S2_SR\" ); var geometry = ee . Geometry . Polygon ( [[[ - 89.79297430041262 , 29.677212347812258 ], [ - 89.79297430041262 , 28.850584616352855 ], [ - 88.91681463244387 , 28.850584616352855 ], [ - 88.91681463244387 , 29.677212347812258 ]]], null , false ); var vis = { \"opacity\" : 1 , \"bands\" : [ \"B8\" , \"B3\" , \"B2\" ], \"min\" : 1 , \"max\" : 2870 , \"gamma\" : 1.4140000000000001 }; var image = ee . Image ( 'COPERNICUS/S2_SR/20190831T162839_20190831T164212_T16RBT' ) print ( 'Single Image' , image ) //Center the Map to the image and add the image Map . centerObject ( geometry , 10 ) Map . addLayer ( image , vis , \"S2-SR Image 2019-08-31\" ) //Clip an image var clipped = image . clip ( geometry ) Map . addLayer ( clipped , vis , \"Clipped S2-SR Image 2019-08-31\" )","title":"Images in Earth Engine"},{"location":"projects/indices/","text":"Collection Maps & Indices \u00b6 Now that we know how to build functions like the cloud mask, what about applying a simple band ratio or an index and adding it back to the image? Mapping over a collection is powerful because it allows you to work efficiently over each image in the collection without needing to aggregate or composite before hand though both approaches can find some use. For this example we are going to run a simple Normalized Difference Vegetation Index over our area of interest and add the results back with a visualization palette. var s2 = ee . ImageCollection ( \"COPERNICUS/S2_SR\" ); var geometry = ee . Geometry . Polygon ( [[[ - 89.79297430041262 , 29.677212347812258 ], [ - 89.79297430041262 , 28.850584616352855 ], [ - 88.91681463244387 , 28.850584616352855 ], [ - 88.91681463244387 , 29.677212347812258 ]]], null , false ); var rgbVis = { \"opacity\" : 1 , \"bands\" : [ \"B4\" , \"B3\" , \"B2\" ], \"min\" : 1 , \"max\" : 1506 , \"gamma\" : 1.786 }; //********************************* Image Collection*****************************************// Map . centerObject ( geometry , 10 ) //Let's constrain the Sentinel-2 SR collection by our geometry & a cloudy pixel percentage metadata var collection = s2 . filter ( ee . Filter . bounds ( geometry )) . filter ( ee . Filter . date ( '2020-01-01' , '2021-01-01' )) . filter ( ee . Filter . lt ( 'CLOUDY_PIXEL_PERCENTAGE' , 5 )) print ( 'Total filtered images in collection' , collection . size ()) //Add all functions in one place // Function to remove cloud and snow pixels from Sentinel-2 SR image function masks2 ( image ) { var cloudProb = image . select ( 'MSK_CLDPRB' ); var snowProb = image . select ( 'MSK_SNWPRB' ); var cloud = cloudProb . lt ( 1 ); var snow = snowProb . lt ( 1 ); var scl = image . select ( 'SCL' ); var shadow = scl . eq ( 3 ); // 3 = cloud shadow var cirrus = scl . eq ( 10 ); // 10 = cirrus // Cloud probability less than 5% or cloud shadow classification var mask = ( cloud . and ( snow )). and ( cirrus . neq ( 1 )). and ( shadow . neq ( 1 )); return image . updateMask ( mask ); } // Write a function that computes NDVI for an image and adds it as a band function addNDVI ( image ) { var ndvi = image . normalizedDifference ([ 'B8' , 'B4' ]). rename ( 'ndvi' ); return image . addBands ( ndvi ); } var palette = [ 'FFFFFF' , 'CE7E45' , 'DF923D' , 'F1B555' , 'FCD163' , '99B718' , '74A901' , '66A000' , '529400' , '3E8601' , '207401' , '056201' , '004C00' , '023B01' , '012E01' , '011D01' , '011301' ]; var ndviVis = { min : 0 , max : 0.5 , palette : palette } collection = collection . map ( masks2 ). map ( addNDVI ) print ( 'Single Image post NDVI' , collection . first ()) /* Things to keep in mind, image collections are usually sorted by default based on date Mosaic function adds the latest pixels or most recent image on top while trying to mosaic Median composite on the other hands takes the median value of pixel over the time period */ var medianComposite = collection . median (); Map . addLayer ( ee . ImageCollection ( collection ). median (). select ( \"ndvi\" ). clip ( geometry ), ndviVis , 'NDVI Median' )","title":"Collection Maps & Indices"},{"location":"projects/indices/#collection-maps-indices","text":"Now that we know how to build functions like the cloud mask, what about applying a simple band ratio or an index and adding it back to the image? Mapping over a collection is powerful because it allows you to work efficiently over each image in the collection without needing to aggregate or composite before hand though both approaches can find some use. For this example we are going to run a simple Normalized Difference Vegetation Index over our area of interest and add the results back with a visualization palette. var s2 = ee . ImageCollection ( \"COPERNICUS/S2_SR\" ); var geometry = ee . Geometry . Polygon ( [[[ - 89.79297430041262 , 29.677212347812258 ], [ - 89.79297430041262 , 28.850584616352855 ], [ - 88.91681463244387 , 28.850584616352855 ], [ - 88.91681463244387 , 29.677212347812258 ]]], null , false ); var rgbVis = { \"opacity\" : 1 , \"bands\" : [ \"B4\" , \"B3\" , \"B2\" ], \"min\" : 1 , \"max\" : 1506 , \"gamma\" : 1.786 }; //********************************* Image Collection*****************************************// Map . centerObject ( geometry , 10 ) //Let's constrain the Sentinel-2 SR collection by our geometry & a cloudy pixel percentage metadata var collection = s2 . filter ( ee . Filter . bounds ( geometry )) . filter ( ee . Filter . date ( '2020-01-01' , '2021-01-01' )) . filter ( ee . Filter . lt ( 'CLOUDY_PIXEL_PERCENTAGE' , 5 )) print ( 'Total filtered images in collection' , collection . size ()) //Add all functions in one place // Function to remove cloud and snow pixels from Sentinel-2 SR image function masks2 ( image ) { var cloudProb = image . select ( 'MSK_CLDPRB' ); var snowProb = image . select ( 'MSK_SNWPRB' ); var cloud = cloudProb . lt ( 1 ); var snow = snowProb . lt ( 1 ); var scl = image . select ( 'SCL' ); var shadow = scl . eq ( 3 ); // 3 = cloud shadow var cirrus = scl . eq ( 10 ); // 10 = cirrus // Cloud probability less than 5% or cloud shadow classification var mask = ( cloud . and ( snow )). and ( cirrus . neq ( 1 )). and ( shadow . neq ( 1 )); return image . updateMask ( mask ); } // Write a function that computes NDVI for an image and adds it as a band function addNDVI ( image ) { var ndvi = image . normalizedDifference ([ 'B8' , 'B4' ]). rename ( 'ndvi' ); return image . addBands ( ndvi ); } var palette = [ 'FFFFFF' , 'CE7E45' , 'DF923D' , 'F1B555' , 'FCD163' , '99B718' , '74A901' , '66A000' , '529400' , '3E8601' , '207401' , '056201' , '004C00' , '023B01' , '012E01' , '011D01' , '011301' ]; var ndviVis = { min : 0 , max : 0.5 , palette : palette } collection = collection . map ( masks2 ). map ( addNDVI ) print ( 'Single Image post NDVI' , collection . first ()) /* Things to keep in mind, image collections are usually sorted by default based on date Mosaic function adds the latest pixels or most recent image on top while trying to mosaic Median composite on the other hands takes the median value of pixel over the time period */ var medianComposite = collection . median (); Map . addLayer ( ee . ImageCollection ( collection ). median (). select ( \"ndvi\" ). clip ( geometry ), ndviVis , 'NDVI Median' )","title":"Collection Maps &amp; Indices"},{"location":"projects/labs_ee/","text":"Lab space \u00b6 If you have a Google Earth Engine account, accept this repository . This will add the code repo to your readers section in Google Earth Engine. This is a more robust method of sharing code since it allows me to make changes and updates and push it directly to everyone as they hit refresh.","title":"Lab space"},{"location":"projects/labs_ee/#lab-space","text":"If you have a Google Earth Engine account, accept this repository . This will add the code repo to your readers section in Google Earth Engine. This is a more robust method of sharing code since it allows me to make changes and updates and push it directly to everyone as they hit refresh.","title":"Lab space"},{"location":"projects/mosaics_composite/","text":"Mosaics & composites \u00b6 One of the most sought after functions in Earth Engine is the possibility of using deep time stack imagery to create cloud free composites. One of the simplest way of thinking about this is to use reducers that we talked about earlier, where we look at an entire stack of pixels and choose the median value of the distribution of pixel across stack and we end up getting a cloud free composite over the given time period. Depending on the number of images, the actual number of cloud free images in the overall stack your results may need more fine tune adjustments. The mosaics function in GEE adds the latest or more recent image on top while trying to mosaic, where composites like median or max are based on the mathematical operation by that name. Mosaics is thereby a more specific compositor which takes into account latest pixel on top first during the mosaic operation or compositing. var s2 = ee . ImageCollection ( \"COPERNICUS/S2_SR\" ); var geometry = ee . Geometry . Polygon ( [[[ - 89.79297430041262 , 29.677212347812258 ], [ - 89.79297430041262 , 28.850584616352855 ], [ - 88.91681463244387 , 28.850584616352855 ], [ - 88.91681463244387 , 29.677212347812258 ]]], null , false ); var rgbVis = { \"opacity\" : 1 , \"bands\" : [ \"B4\" , \"B3\" , \"B2\" ], \"min\" : 1 , \"max\" : 1506 , \"gamma\" : 1.786 }; //********************************* Image Collection*****************************************// Map . centerObject ( geometry , 10 ) //Let's constrain the Sentinel-2 SR collection by our geometry & a cloudy pixel percentage metadata var collection = s2 . filter ( ee . Filter . bounds ( geometry )) . filter ( ee . Filter . date ( '2020-01-01' , '2021-01-01' )) . filter ( ee . Filter . lt ( 'CLOUDY_PIXEL_PERCENTAGE' , 5 )) . select ( 'B.*' ) //Also let us only add optical bands wildcard to filter only bands starting with B print ( 'Total filter images in collection' , collection . size ()) /* Things to keep in mind, image collections are usually sorted by default based on date Mosaic function adds the latest pixels or most recent image on top while trying to mosaic Median composite on the other hands takes the median value of pixel over the time period */ var mosaic = collection . mosaic () var medianComposite = collection . median (); Map . addLayer ( collection , rgbVis , 'Filtered Collection' ); Map . addLayer ( mosaic . clip ( geometry ), rgbVis , 'Mosaic' , false ); Map . addLayer ( medianComposite . clip ( geometry ), rgbVis , 'Median Composite' , false )","title":"Mosaics and composites"},{"location":"projects/mosaics_composite/#mosaics-composites","text":"One of the most sought after functions in Earth Engine is the possibility of using deep time stack imagery to create cloud free composites. One of the simplest way of thinking about this is to use reducers that we talked about earlier, where we look at an entire stack of pixels and choose the median value of the distribution of pixel across stack and we end up getting a cloud free composite over the given time period. Depending on the number of images, the actual number of cloud free images in the overall stack your results may need more fine tune adjustments. The mosaics function in GEE adds the latest or more recent image on top while trying to mosaic, where composites like median or max are based on the mathematical operation by that name. Mosaics is thereby a more specific compositor which takes into account latest pixel on top first during the mosaic operation or compositing. var s2 = ee . ImageCollection ( \"COPERNICUS/S2_SR\" ); var geometry = ee . Geometry . Polygon ( [[[ - 89.79297430041262 , 29.677212347812258 ], [ - 89.79297430041262 , 28.850584616352855 ], [ - 88.91681463244387 , 28.850584616352855 ], [ - 88.91681463244387 , 29.677212347812258 ]]], null , false ); var rgbVis = { \"opacity\" : 1 , \"bands\" : [ \"B4\" , \"B3\" , \"B2\" ], \"min\" : 1 , \"max\" : 1506 , \"gamma\" : 1.786 }; //********************************* Image Collection*****************************************// Map . centerObject ( geometry , 10 ) //Let's constrain the Sentinel-2 SR collection by our geometry & a cloudy pixel percentage metadata var collection = s2 . filter ( ee . Filter . bounds ( geometry )) . filter ( ee . Filter . date ( '2020-01-01' , '2021-01-01' )) . filter ( ee . Filter . lt ( 'CLOUDY_PIXEL_PERCENTAGE' , 5 )) . select ( 'B.*' ) //Also let us only add optical bands wildcard to filter only bands starting with B print ( 'Total filter images in collection' , collection . size ()) /* Things to keep in mind, image collections are usually sorted by default based on date Mosaic function adds the latest pixels or most recent image on top while trying to mosaic Median composite on the other hands takes the median value of pixel over the time period */ var mosaic = collection . mosaic () var medianComposite = collection . median (); Map . addLayer ( collection , rgbVis , 'Filtered Collection' ); Map . addLayer ( mosaic . clip ( geometry ), rgbVis , 'Mosaic' , false ); Map . addLayer ( medianComposite . clip ( geometry ), rgbVis , 'Median Composite' , false )","title":"Mosaics &amp; composites"},{"location":"projects/setup/","text":"Setting up your Accounts \u00b6 Registering for a Google Earth Engine Account \u00b6 If you don\u2019t have a developer account sign up for one here and make sure you follow the instructions to install the python CLI. The API and the CLI gets updated frequently and as does the install process as needed so you can read the latest instructions at the page. Getting Help with Google Earth Engine \u00b6 Google Earth Engine maintain a developer page for you to find out more information,test tutorials along with housing a few quick FAQ(s) Earth Engine Developers Page Earth Engine Community Resources","title":"Setting up your Accounts"},{"location":"projects/setup/#setting-up-your-accounts","text":"","title":"Setting up your Accounts"},{"location":"projects/setup/#registering-for-a-google-earth-engine-account","text":"If you don\u2019t have a developer account sign up for one here and make sure you follow the instructions to install the python CLI. The API and the CLI gets updated frequently and as does the install process as needed so you can read the latest instructions at the page.","title":"Registering for a Google Earth Engine Account"},{"location":"projects/setup/#getting-help-with-google-earth-engine","text":"Google Earth Engine maintain a developer page for you to find out more information,test tutorials along with housing a few quick FAQ(s) Earth Engine Developers Page Earth Engine Community Resources","title":"Getting Help with Google Earth Engine"}]}